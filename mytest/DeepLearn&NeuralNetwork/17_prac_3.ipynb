{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, LeakyReLU, Dropout, Input, BatchNormalization\n",
    "from keras.layers import Reshape, Conv2D, Conv2DTranspose, Flatten, Activation\n",
    "from keras.models import Model,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 텐서 플로의 정보 출력 억제하기\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # GPU 장치 지정\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)   # 이거 쓰지 마셈 ㅈㄴ 출력 더러움\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"감지된 GPU가 없습니다. GPU가 없으면 LSTM과 CNN이 매우 느릴 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.\n",
    "_연습문제: 이미지 데이터셋을 처리하는 DCGAN을 훈련하고 이를 사용해 이미지를 생성해보세요. 경험 재생을 추가하고 도움이 되는지 확인하세요. 생성된 클래스를 제어할 수 있는 조건 GAN으로 바꾸어 시도해보세요._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset\n",
    "\n",
    "* 'generator'의 'tanh' Activation 출력에 적합하도록 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Noramlization\n",
    "X_train = X_train.astype(np.float32) / 127.5 - 1\n",
    "\n",
    "# Reshape\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'generator' Model\n",
    "- 랜덤 벡터(잠재공간의 랜덤 포인트)를 입력받아 이미지 생성 \n",
    "    - NOISE_DIM : 입력 랜덤 벡터 크기\n",
    "- 'discriminator'를 속이도록 학습\n",
    "    - 'Real Image'와 같은 'Fake Image' 생성이 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOISE_DIM = 10\n",
    "\n",
    "generator = Sequential(name = 'generator')\n",
    "\n",
    "generator.add(Dense(256 * 7 * 7, input_shape = (NOISE_DIM,)))\n",
    "generator.add(LeakyReLU())\n",
    "# 12544\n",
    "generator.add(Reshape((7, 7, 256)))\n",
    "# (14, 14, 128) 25088\n",
    "generator.add(Conv2DTranspose(128, kernel_size = 3,\n",
    "                              strides = 2,\n",
    "                              padding = 'same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU())\n",
    "# (28, 28, 64) 50176\n",
    "generator.add(Conv2DTranspose(64, kernel_size = 3,\n",
    "                              strides = 2,\n",
    "                              padding = 'same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU())\n",
    "# (28, 28, 1)\n",
    "generator.add(Conv2D(1, kernel_size = 3, padding='same'))\n",
    "generator.add(Activation('tanh'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "NOISE_DIM = 10\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(256 * 7 * 7, input_shape=[NOISE_DIM]),\n",
    "    keras.layers.Reshape(7, 7, 256),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=3, strides=2,padding ='SAME',\n",
    "                                 activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='SAME', \n",
    "                                 activation=\"tanh\")],\n",
    "    name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'discriminator' Model\n",
    "\n",
    "- 이미지를 입력받아 'Real Image'인지 'generator'가 생성한 'Fake Image'인지 판별\n",
    "    - 이진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "discriminator = Sequential(name = 'discriminator')\n",
    "\n",
    "discriminator.add(Conv2D(32, kernel_size = 3,\n",
    "                         strides = 2,\n",
    "                         padding = 'same',\n",
    "                         input_shape = (28, 28, 1)))\n",
    "discriminator.add(LeakyReLU())\n",
    "discriminator.add(Dropout(0.5))\n",
    "\n",
    "discriminator.add(Conv2D(64, kernel_size = 3,strides = 2,\n",
    "                         padding = 'same'))\n",
    "discriminator.add(LeakyReLU())\n",
    "\n",
    "discriminator.add(Conv2D(128, kernel_size=3,\n",
    "                         strides=2,\n",
    "                         padding='same'))\n",
    "discriminator.add(LeakyReLU())\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Flatten() )\n",
    "discriminator.add(Dense(1, activation = 'sigmoid'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Conv2D(32, kernel_size=3, strides=2, padding='SAME', \n",
    "                        activation=keras.layers.LeakyReLU(0.2),\n",
    "                        input_shape=[28, 28, 1]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='SAME', \n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    \n",
    "    keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='SAME', \n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")], \n",
    "    name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'discriminator' Compile\n",
    "- 학습 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'adam' Optimizer\n",
    "- beta_1 : 감쇠율 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'GAN' Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'generator', 'discriminator' 연결\n",
    "- 'gan' 모델에서 'generator'만 학습하도록 설정\n",
    "    - disciriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "# gan_input = Input(shape=(NOISE_DIM,))\n",
    "# x = generator(gan_input) # generator\n",
    "# output = discriminator(x) # discriminator\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'gan' Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan = Model(gan_input, output, name='gan')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'gan' Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define 'get_batches()' Function\n",
    "- MNIST image batch 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size):\n",
    "    batches = []\n",
    "\n",
    "    for i in range(data.shape[0] // batch_size): # epoch\n",
    "        batch = data[i * batch_size : (i + 1) * batch_size]\n",
    "        batches.append(batch)\n",
    "    \n",
    "    return np.asarray(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'visualize_training()' Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(epoch, d_losses, g_losses):\n",
    "  \n",
    "    # 오차 시각화\n",
    "    # plt.figure(figsize=(8, 4))\n",
    "    # plt.plot(d_losses, label='Discriminator Loss')\n",
    "    # plt.plot(g_losses, label='Generatror Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    # print('epoch: {}, Discriminator Loss: {}, Generator Loss: {}'.format(epoch, np.asarray(d_loss\n",
    "\n",
    "    # 이미지 생성 결과 시각화\n",
    "    print('epoch :', epoch)\n",
    "    noise = np.random.normal(0, 1, size = (24, NOISE_DIM))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(-1, 28, 28)\n",
    "    \n",
    "    plt.figure(figsize = (8, 4))\n",
    "    \n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(4, 6, i + 1)\n",
    "        plt.imshow(generated_images[i], interpolation = 'nearest', cmap = 'Greys_r')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = keras.losses.BinaryCrossentropy()\n",
    "# train_loss = keras.metrics.BinaryCrossentropy(name = 'train_loss')\n",
    "# train_accuracy = keras.metrics.BinaryAccuracy(name = 'train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "- 약 25분 \n",
    "\n",
    "- .fit( )\n",
    "    - 'epoch', 'batch_size' 지정 \n",
    "- .train_on_batch( )\n",
    "    - 전달 받은 모든 데이터를 사용하여 학습 진행\n",
    "- 'generator'가 매번 새로운 'Fake Image'를 생성하여 '.train_on_batch( )' 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 'discriminator', 'gan' Loss 저장 List \n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1): \n",
    "    # batch 별 학습\n",
    "    for real_images in get_batches(X_train, BATCH_SIZE):\n",
    "        # Random Noise 생성\n",
    "        input_noise = np.random.uniform(-1, 1, size = [BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "        # Fake Image 데이터 생성\n",
    "        generated_images = generator.predict(input_noise)\n",
    "\n",
    "        # 'gan' 학습용 X 데이터 정의\n",
    "        x_dis = np.concatenate([real_images, generated_images])\n",
    "\n",
    "        # 'gan' 학습용 y 데이터 정의\n",
    "        y_dis = np.zeros(2 * BATCH_SIZE) \n",
    "        y_dis[:BATCH_SIZE] = 1\n",
    "        \n",
    "        # 'discriminator' 학습\n",
    "        discriminator.trainable = True\n",
    "        d_loss = discriminator.train_on_batch(x_dis, y_dis)\n",
    "\n",
    "        # 'gan' 학습\n",
    "        noise = np.random.uniform(-1, 1, size = [BATCH_SIZE, NOISE_DIM]) \n",
    "        y_gan = np.ones(BATCH_SIZE)\n",
    "\n",
    "        # 'discriminator' 학습 정지 \n",
    "        discriminator.trainable = False\n",
    "        g_loss = gan.train_on_batch(noise, y_gan)\n",
    "    \n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_loss)\n",
    "\n",
    "    # 생성 결과 시각화\n",
    "    if epoch == 1 or epoch % 5 == 0:\n",
    "        visualize_training(epoch, d_losses, g_losses)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "813af78ecda15588a7e82817c6b6453ec390e9c163778a4ec46b9b973fd11dd3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf_pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
