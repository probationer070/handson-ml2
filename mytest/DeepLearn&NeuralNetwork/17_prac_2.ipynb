{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 텐서 플로의 정보 출력 억제하기\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # GPU 장치 지정\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)   # 이거 쓰지 마셈 ㅈㄴ 출력 더러움\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"감지된 GPU가 없습니다. GPU가 없으면 LSTM과 CNN이 매우 느릴 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.\n",
    "_연습문제: 이미지 데이터셋을 하나 선택해 변이형 오토인코더를 훈련하고 이미지를 생성해보세요. 또는 관심있는 레이블이 없는 데이터셋을 찾아서 새로운 샘플을 생성할 수 있는지 확인해 보세요._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "X_train = X_train.reshape(60000, 28 * 28)\n",
    "X_test = X_test.reshape(10000, 28 * 28)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Modeling with Fuctional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Latent Space' Point Mapping\n",
    "\n",
    "- 각 이미지가 '잠재공간(Latent Space) 포인트' 주변의 '다변수 정규 분포(Mutilvariate Nodrmal Distribution)'에 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "input_img = Input(shape = (784,))\n",
    "encoded = Dense(256, activation = 'elu')(input_img)\n",
    "encoded = Dense(128, activation = 'elu')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variational(Latent Space) Layers\n",
    "    - 평균(mean)과 분산(log_var)으로 인코딩된 잠재공간(Latent Space) 포인트 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = Dense(2, name = 'mean')(encoded)\n",
    "log_var = Dense(2, name = 'var')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Latent Space' Sampling\n",
    "\n",
    "- 잠재공간(Latent Space)의 잠재공간-포인트(z) 샘플링 \n",
    "    - 정규분포상에서 무작위로 선택한 'epsilon'값 사용\n",
    "        - Encoding 결과값을 그대로 사용하면 항상 같은 결과만 생성\n",
    "        - 따라서 랜덤 샘플링을 통하여 기존 Data에 존재하지 않는 새로운 Image 생성\n",
    "- Lambda( ) : 임의의 파이썬 함수 객체를 Keras Layer로 생성 \n",
    "- K.exp(log_var) : 로그분산 -> 표준편차 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "def sampling(args):\n",
    "    mean, log_var = args\n",
    "    epsilon = K.random_normal(shape = (100, 2), mean = 0., stddev = 1.0)\n",
    "    \n",
    "    return mean + K.exp(log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape = (2,))([mean, log_var]) # Lambda를 사용하면 output이 2개로 나가는 Layer를 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'encoder' Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.models.Model(input_img, mean) # 모델을 만들 때는 mean 만 출력으로 사용(평균만 뽑아내면 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'generator' Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoding Layer Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오토 인코더 모양으로 똑같이 보여주기 위해 3개 층으로 만들었으나, 인코더랑 층의 개수가 동일하지 않아도 됨\n",
    "decoder_1 = Dense(128, activation = 'elu')\n",
    "decoder_2 = Dense(256, activation = 'elu')\n",
    "decoder_3 = Dense(784, activation = 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 랜덤 샘플링 '잠재공간-포인트(Z)' 재구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sample = decoder_1(z)\n",
    "z_sample = decoder_2(z_sample)\n",
    "z_sample = decoder_3(z_sample)\n",
    "\n",
    "z_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generator Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape = (2,))\n",
    "y_gen = decoder_1(decoder_input)\n",
    "y_gen = decoder_2(y_gen)\n",
    "y_gen = decoder_3(y_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build 'generator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.models.Model(decoder_input, y_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'vae' Model Dense\n",
    "\n",
    "- Build 'vae' Model\n",
    "    - End-to-End AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = keras.models.Model(input_img, z_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compile\n",
    "\n",
    "\n",
    "\n",
    "- Define 'vae_loss'\n",
    "    - reconstruction_loss : 입력값 재구성 손실\n",
    "        - **Generator의 Loss**\n",
    "        - 원본 이미지와 생성된 이미지와의 오차(CEE) \n",
    "        - '샘플링 함수'로 생성한 'z' 값으로 얼마나 원본이미지와 유사한 이미지를 잘 생성 하는가?\n",
    "    - kl_loss : 사전 분포와 잠재 분포 사이의 Kullback Leibler-Divergence(두 확률분포 간 거리)\n",
    "        - **Encoder의 Loss**\n",
    "        - 사전 분포(Prior Distribution) : 원본 이미지 확률분포\n",
    "        - 잠재 분포(Latent Distribution) : 잠재공간 확률분포 \n",
    "        - '샘플링 함수'의 값(z)이 원본 이미지의 확률분포와 유사한가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추가 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import objectives\n",
    "\n",
    "reconstruction_loss = objectives.binary_crossentropy(input_img, z_sample)\n",
    "kl_loss = 0.0005 * K.mean(K.square(mean) + K.exp(log_var) - log_var - 1, axis = -1)\n",
    "vae_loss = reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.add_loss(vae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compile with vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vae.fit(X_train,\n",
    "       shuffle = True,\n",
    "       epochs = 300,\n",
    "       batch_size = 100,\n",
    "       validation_data = (X_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Latent Space' Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes in the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_latent = encoder.predict(X_test, batch_size = 100)\n",
    "plt.figure(figsize = (12, 10))\n",
    "plt.scatter(X_test_latent[:, 0], X_test_latent[:, 1], c = y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display 2D Manifold(20 * 20)\n",
    "- 두 개의 '개념 벡터(Concept Vector)'로 데이터의 특징을 '표현(Representation)' \n",
    "    - 두께, 회전각도 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "n = 20\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(figure, cmap = 'Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'generator' Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_latent = encoder.predict(X_test)  # 'encoder' Test(784 -> 2)\n",
    "encoded_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_imgs = generator.predict(encoded_latent)  # 'generator' Test(2 -> 784)\n",
    "generated_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Visualization\n",
    "- 복원이 아닌 '생성된' 이미지들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize = (20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(generated_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
