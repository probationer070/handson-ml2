{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "### a.\n",
    "_문제: (10장에서 소개한) 패션 MNIST 데이터셋을 적재하고 훈련 세트, 검증 세트, 테스트\n",
    "세트로 나눕니다. 훈련 세트를 섞은 다음 각 데이터셋을 TFRecord 파일로 저장합니\n",
    "다. 각 레코드는 두 개의 특성을 가진 `Example` 프로토콜 버퍼, 즉 직렬화된 이미지(`tf.io.serialize_tensor()`를 사용해 이미지를 직렬화하세요)와 레이블입니다. 참고: 용량이 큰 이미지일 경우 `tf.io.encode_jpeg()`를 사용할 수 있습니다. 많은 공간을 절약할 수 있지만 이미지 품질이 손해를 봅니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(28, 28), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아니 ㅅㅂ 왜 되는데 TFRecord 안되서 다른 걸로 시도해도 no feature ㅇㅈㄹ 했는데 갑자기 됨. ㅅㅂ?\n",
    "\n",
    "오류 내용 :\n",
    "\n",
    "NameError: name 'Example' is not defined\n",
    "\n",
    "ValueError: Protocol message Feature has no \"feature\" field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "# 반드시 이렇게 임포트 해줘야 하는 듯 ?\n",
    "\n",
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    #image_data = tf.io.encode_jpeg(image[..., np.newaxis])\n",
    "    ex_contents = Example(\n",
    "                features=Features(\n",
    "                    feature={\n",
    "                        \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                        \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "                    }))\n",
    "    return ex_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_example_fixed(image, label):\n",
    "#     image_data = tf.io.serialize_tensor(image)\n",
    "#     #image_data = tf.io.encode_jpeg(image[..., np.newaxis])\n",
    "#     output = tf.train.Example(\n",
    "#         features=tf.train.Feature(\n",
    "#             feature={\n",
    "#                 \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_data.numpy()])),\n",
    "#                 \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "#             }))\n",
    "    \n",
    "#     return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, label in valid_set.take(1):\n",
    "#     print(create_example_fixed(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 함수는 주어진 데이터셋을 일련의 TFRecord 파일로 저장합니다. 이 예제는 라운드-로빈 방식으로 파일에 저장합니다. 이를 위해 `dataset.enumerate()` 메서드로 모든 샘플을 순회하고 저장할 파일을 겨정하기 위해 `index % n_shards`를 계산합니다. 표준 `contextlib.ExitStack` 클래스를 사용해 쓰는 동안 I/O 에러의 발생 여부에 상관없이 모든 `writer`가 적절히 종료되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "             for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                   for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_문제: tf.data로 각 세트를 위한 효율적인 데이터셋을 만듭니다. 마지막으로 이 데이터셋으로\n",
    "입력 특성을 표준화하는 전처리 층을 포함한 케라스 모델을 훈련합니다. 텐서보드로 프로파일 데이터를 시각화하여 가능한 한 입력 파이프라인을 효율적으로 만들어보세요._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)    # 위에서 정의한 대로 파싱\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)         # tensor로 변환\n",
    "    #image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,    # 병렬로 읽을 파일 수 : num_parallel_reads\n",
    "                                      num_parallel_reads=n_read_threads) \n",
    "    if cache:\n",
    "        dataset = dataset.cache() # 각 에포크 동안 실행되는 일부 작업 저장 ?\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):     # -> 입력특성 표준화  \n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "# 각 특성의 평균을 빼고 표준편차로 나눔. 0으로 나누는 것을 방지하기 위해 작은 수를 더함. \n",
    "\n",
    "\n",
    "standardization = Standardization(input_shape=[28, 28])\n",
    "# or perhaps soon:\n",
    "#standardization = keras.layers.Normalization()\n",
    "\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)    # standardization 층을 모델에 추가하기 전에 \n",
    "                                        # 데이터 샘플과 함께 adapt()호출\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 21s 11ms/step - loss: 570.1453 - accuracy: 0.8415 - val_loss: 149.1328 - val_accuracy: 0.8670\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 639.2181 - accuracy: 0.8785 - val_loss: 282.7338 - val_accuracy: 0.8730\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 98.2001 - accuracy: 0.8905 - val_loss: 0.3451 - val_accuracy: 0.8790\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 437.1323 - accuracy: 0.9012 - val_loss: 152.0194 - val_accuracy: 0.8812\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 198.3816 - accuracy: 0.9077 - val_loss: 88.0071 - val_accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d88a9cb7c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "logs = os.path.join(os.curdir, \"my_logs\",   # my_logs 파일에 실시간으로 데이터를 만들고 담음\n",
    "                    \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(            # 텐서보드 출력을 위한 데이터 콜백\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11284), started 5 days, 2:11:58 ago. (Use '!kill 11284' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9197042df18e758a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9197042df18e758a\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.\n",
    "_문제: 이 연습문제에서 데이터셋을 다운로드 및 분할하고 `tf.data.Dataset` 객체를 만들어 데이터를 적재하고 효율적으로 전처리하겠습니다. 그다음 `Embedding` 층을 포함한 이진 분류 모델을 만들고 훈련시킵니다._\n",
    "\n",
    "### a.\n",
    "_문제: [인터넷 영화 데이터베이스](https://imdb.com/)의 영화 리뷰 50,000개를 담은 [영화 리뷰\n",
    "데이터셋](https://homl.info/imdb)을 다운로드합니다. 이 데이터는\n",
    "`train`과 `test`라는 두 개의 디렉터리로 구성되어 있습니다. 각 디렉터리에는 12,500개의 긍정 리뷰를 담은 `pos` 서브디렉터리와 12,500개의 부정 리뷰를 담은 `neg` 서브디렉터리가 있습니다. 리뷰는 각각 별도의 텍스트 파일에 저장되어 있습니다. (전처리된 BOW를 포함해) 다른 파일과 디렉터리가 있지만 이 연습문제에서는 무시합니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/NICE/.keras/datasets/aclImdb')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "FILENAME = \"aclImdb_v1.tar.gz\"\n",
    "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n",
    "path = Path(filepath).parent / \"aclImdb\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\\\n",
      "    README\n",
      "    imdb.vocab\n",
      "    imdbEr.txt\n",
      "    test\\\n",
      "        labeledBow.feat\n",
      "        urls_neg.txt\n",
      "        urls_pos.txt\n",
      "        neg\\\n",
      "            0_2.txt\n",
      "            10000_4.txt\n",
      "            10001_1.txt\n",
      "            ...\n",
      "        pos\\\n",
      "            0_10.txt\n",
      "            10000_7.txt\n",
      "            10001_9.txt\n",
      "            ...\n",
      "    train\\\n",
      "        labeledBow.feat\n",
      "        unsupBow.feat\n",
      "        urls_neg.txt\n",
      "        ...\n",
      "        neg\\\n",
      "            0_3.txt\n",
      "            10000_4.txt\n",
      "            10001_4.txt\n",
      "            ...\n",
      "        pos\\\n",
      "            0_9.txt\n",
      "            10000_8.txt\n",
      "            10001_10.txt\n",
      "            ...\n",
      "        unsup\\\n",
      "            0_0.txt\n",
      "            10000_0.txt\n",
      "            10001_0.txt\n",
      "            ...\n"
     ]
    }
   ],
   "source": [
    "for name, subdirs, files in os.walk(path):\n",
    "    indent = len(Path(name).parts) - len(path.parts)\n",
    "    print(\"    \" * indent + Path(name).parts[-1] + os.sep)\n",
    "    for index, filename in enumerate(sorted(files)):\n",
    "        if index == 3:\n",
    "            print(\"    \" * (indent + 1) + \"...\")\n",
    "            break\n",
    "        print(\"    \" * (indent + 1) + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_문제: 테스트 세트를 검증 세트(15,000개)와 테스트 세트(10,000개)로 나눕니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(test_valid_pos)\n",
    "\n",
    "test_pos = test_valid_pos[:5000]  # 5000개\n",
    "test_neg = test_valid_neg[:5000]  # 5000개\n",
    "valid_pos = test_valid_pos[5000:] # 7500개\n",
    "valid_neg = test_valid_neg[5000:] # 7500개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "_문제: tf.data를 사용해 각 세트에 대한 효율적인 데이터셋을 만듭니다._\n",
    "\n",
    "이 데이터셋을 메모리에 적재할 수 있으므로 파이썬 코드와 `tf.data.Dataset.from_tensor_slices()`를 사용해 모든 데이터를 적재합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)): \n",
    "        # 1번째 부정 리뷰 반복, 2번째 긍정 리뷰 반복\n",
    "        for filepath in filepaths:  \n",
    "            with open(filepath) as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices(      # 각 요소마다 reviews와 labels 리스트 존재\n",
    "        (tf.constant(reviews), tf.constant(labels)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!', shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.', shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b'Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I\\'m a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).', shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터셋을 적재하고 10회 반복하는데 약 17초가 걸립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 이 데이터셋이 메모리에 맞지 않는다고 가정하고 좀 더 재미있는 것을 만들어 보죠. 다행히 각 리뷰는 한 줄로 되어 있기 때문에(`<br />`로 줄바꿈됩니다) `TextLineDataset`를 사용해 리뷰를 읽을 수 있습니다. 그렇지 않으면 입력 파일을 전처리해야 합니다(예를 들어, TFRecord로 바꿉니다). 매우 큰 데이터셋의 경우 아파치 빔(Apache Beam) 같은 도구를 사용하는 것이 합리적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n",
    "    dataset_neg = tf.data.TextLineDataset(filepaths_negative,\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))   # 대략 이런 식 [\"review\", '0']\n",
    "    dataset_pos = tf.data.TextLineDataset(filepaths_positive,   # 아마 0은 부정, 1은 긍정\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))   # [\"review\", '1']\n",
    "    return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)    # 데이터를 아예 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).cache().repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = imdb_dataset(train_pos, train_neg).shuffle(25000).batch(batch_size).prefetch(1)\n",
    "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "_문제: 리뷰를 전처리하기 위해 `TextVectorization` 층을 사용한 이진 분류 모델을 만드세요.\n",
    "`TextVectorization` 층을 아직 사용할 수 없다면 (또는 도전을 좋아한다면) 사용자 전처리 층을 만들어보세요. `tf.strings` 패키지에 있는 함수를 사용할 수 있습니다. 예를 들어 `lower()`로 소문자로 만들거나 `regex_replace()`로 구두점을 공백으로 바꾸고 `split()`로 공백을 기준으로 단어를 나눌 수 있습니다. 룩업 테이블을 사용해 단어 인덱스를 출력하세요. `adapt()` 메서드로 미리 층을 적응시켜야 합니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 리뷰를 전처리하는 함수를 만듭니다. 이 함수는 리뷰를 300자로 자르고 소문자로 변환합니다. 그다음 `<br />`와 글자가 아닌 모든 문자를 공백으로 바꾸고 리뷰를 단어로 분할해 마지막으로 각 리뷰가 `n_words` 개수의 토큰이 되도록 패딩하거나 잘라냅니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=string, numpy=\n",
       "array([[b'it', b's', b'a', b'great', b'great', b'movie', b'i', b'loved',\n",
       "        b'it', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "       [b'it', b'was', b'terrible', b'run', b'away', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>']], dtype=object)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(X_batch, n_words=50):\n",
    "    shape = tf.shape(X_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])\n",
    "    Z = tf.strings.substr(X_batch, 0, 300)      # 300chars per 1 review \n",
    "    Z = tf.strings.lower(Z)                     # lowercase\n",
    "    Z = tf.strings.regex_replace(Z, b\"<br\\\\s*/?>\", b\" \")    # any chars other than \"<br />\" & \"words\" \n",
    "    Z = tf.strings.regex_replace(Z, b\"[^a-z]\", b\" \")        # with black \n",
    "    Z = tf.strings.split(Z)\n",
    "    return Z.to_tensor(shape=shape, default_value=b\"<pad>\")\n",
    "\n",
    "X_example = tf.constant([\"It's a great, great movie! I loved it.\", \"It was terrible, run away!!!\"])\n",
    "preprocess(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `preprocess()` 함수의 출력과 동일한 포맷의 데이터 샘플을 입력받는 두 번째 유틸리티 함수를 만듭니다. 이 함수는 가장 빈번한 `max_size` 개수의 단어로 된 리스트를 출력합니다. 가장 흔한 단어는 패딩 토큰입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>',\n",
       " b'it',\n",
       " b'great',\n",
       " b's',\n",
       " b'a',\n",
       " b'movie',\n",
       " b'i',\n",
       " b'loved',\n",
       " b'was',\n",
       " b'terrible',\n",
       " b'run',\n",
       " b'away']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_vocabulary(data_sample, max_size=1000):     # Most printed words, Max_size_save\n",
    "    preprocessed_reviews = preprocess(data_sample).numpy()\n",
    "    counter = Counter()\n",
    "    for words in preprocessed_reviews:\n",
    "        for word in words:\n",
    "            if word != b\"<pad>\":\n",
    "                counter[word] += 1\n",
    "    return [b\"<pad>\"] + [word for word, count in counter.most_common(max_size)]\n",
    "\n",
    "get_vocabulary(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `TextVectorization` 층을 만들 준비가 되었습니다. 이 층의 생성자는 단순하게 하이퍼파라미터(`max_vocabulary_size`와 `n_oov_buckets`)를 저장하는 역할만 수행합니다. `adapt()` 메서드는 `get_vocabulary()` 함수를 사용해 어휘 사전을 계산합니다. 그다음 `StaticVocabularyTable`를 만듭니다(16장에서 자세히 설명합니다). `call()` 메서드는 각 리뷰의 단어 리스트를 패딩합니다. 그다음 `StaticVocabularyTable`를 사용해 어휘 사전에 있는 단어의 인덱스를 조회합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorization(keras.layers.Layer):\n",
    "    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.max_vocabulary_size = max_vocabulary_size\n",
    "        self.n_oov_buckets = n_oov_buckets\n",
    "\n",
    "    def adapt(self, data_sample):\n",
    "        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)\n",
    "        words = tf.constant(self.vocab)\n",
    "        word_ids = tf.range(len(self.vocab), dtype=tf.int64)\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "        self.table = tf.lookup.StaticVocabularyTable(vocab_init, self.n_oov_buckets)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        preprocessed_inputs = preprocess(inputs)\n",
    "        return self.table.lookup(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 정의한 `X_example`로 테스트해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[ 1,  3,  4,  2,  2,  5,  6,  7,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  8,  9, 10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0]], dtype=int64)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization = TextVectorization()\n",
    "\n",
    "text_vectorization.adapt(X_example)\n",
    "text_vectorization(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다! 여기에서 볼 수 있듯이 각 리뷰는 정제되고 토큰화되었습니다. 각 단어는 어휘 사전의 인덱스로 인코딩됩니다(0은 `<pad>` 토큰입니다).\n",
    "\n",
    "이제 또 다른 `TextVectorization` 층을 만들고 전체 IMDB 훈련 세트에 적용해 보겠습니다(훈련 세트가 메모리에 맞지 않으면 `train_set.take(500)`처럼 일부 데이터만 사용할 수 있습니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocabulary_size = 1000\n",
    "n_oov_buckets = 100\n",
    "\n",
    "sample_review_batches = train_set.map(lambda review, label: review)\n",
    "sample_reviews = np.concatenate(list(sample_review_batches.as_numpy_iterator()),\n",
    "                                axis=0)\n",
    "\n",
    "text_vectorization = TextVectorization(max_vocabulary_size, n_oov_buckets,\n",
    "                                       input_shape=[])\n",
    "text_vectorization.adapt(sample_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일하게 `X_example`로 실행해 보죠. 어휘 사전이 크기 때문에 단어의 ID가 큽니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[  9,  14,   2,  64,  64,  12,   5, 256,   9,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  9,  13, 269, 530, 334,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다. 그럼 어휘 사전에서 처음 10개 단어를 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>', b'the', b'a', b'of', b'and', b'i', b'to', b'is', b'this', b'it']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 단어가 리뷰에서 가장 많이 등장하는 단어입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 만들기 위해 모든 단어 ID를 어떤 식으로 인코딩해야 합니다. 한가지 방법은 BoW(bag of words)입니다. 어휘 사전에 있는 각 단어에 대해 리뷰에 단어가 등장하는 횟수를 카운트합니다. 예를 들면 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[2., 2., 0., 1.],\n",
       "       [3., 0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_example = tf.constant([[1, 3, 1, 0, 0], [2, 2, 0, 0, 0]])\n",
    "tf.reduce_sum(tf.one_hot(simple_example, 4), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 리뷰에는 단어 0이 두 번 등장하고, 단어 1도 두 번, 단어 2는 0번, 단어 3은 한 번 등장합니다. 따라서 BoW 표현은 `[2, 2, 0, 1]`입니다. 비슷하게 두 번째 리뷰에는 단어 0이 세 번, 단어 1이 0번 등장하는 식입니다. 이 로직을 간단한 사용자 정의 층으로 구현해서 테스트해 보겠습니다. 단어 0은 `<pad>` 토큰에 해당하므로 카운트하지 않겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords(keras.layers.Layer):\n",
    "    def __init__(self, n_tokens, dtype=tf.int32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.n_tokens = n_tokens\n",
    "    def call(self, inputs):\n",
    "        one_hot = tf.one_hot(inputs, self.n_tokens)\n",
    "        return tf.reduce_sum(one_hot, axis=1)[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2., 0., 1.],\n",
       "       [0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = BagOfWords(n_tokens=4)\n",
    "bag_of_words(simple_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 동작하네요! 이제 훈련 세트의 어휘 사전 크기를 지정한 `BagOfWord` 객체를 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = max_vocabulary_size + n_oov_buckets + 1 # add 1 for <pad>\n",
    "bag_of_words = BagOfWords(n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 훈련할 차례입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 18s 19ms/step - loss: 0.5428 - accuracy: 0.7183 - val_loss: 0.5119 - val_accuracy: 0.7413\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 20s 22ms/step - loss: 0.4703 - accuracy: 0.7713 - val_loss: 0.5052 - val_accuracy: 0.7435\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 16s 17ms/step - loss: 0.4177 - accuracy: 0.8043 - val_loss: 0.5184 - val_accuracy: 0.7387\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 17s 19ms/step - loss: 0.3429 - accuracy: 0.8551 - val_loss: 0.5428 - val_accuracy: 0.7367\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 16s 17ms/step - loss: 0.2588 - accuracy: 0.9040 - val_loss: 0.5816 - val_accuracy: 0.7329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2da1ae214e0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    bag_of_words,\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 에포크에서 검증 세트에 대해 73.5% 정확도를 얻었습니다. 하지만 더 진전이 없습니다. 16장에서 이를 더 개선해 보겠습니다. 지금은 `tf.data`와 케라스 전처리 층으로 효율적인 전처리를 수행하는 것에만 초점을 맞추었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "_문제: `Embedding` 층을 추가하고 단어 개수의 제곱근을 곱하여 리뷰마다 평균 임베딩을 계산하세요(16장 참조). 이제 스케일이 조정된 이 평균 임베딩을 모델의 다음 부분으로 전달할 수 있습니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 리뷰의 평균 임베딩을 계산하고 리뷰에 있는 단어 개수의 제곱근을 곱하기 위해 간단한 함수를 정의합니다. 각 문장에 대해서 이 함수는 $M \\times \\sqrt N$을 계산합니다. 여기에서 $M$은 (패딩 토큰을 제외하고) 문장에 있는 모든 단어 임베딩의 평균입니다. $N$은 (패딩 토큰을 제외한) 문장에 있는 단어의 개수입니다. $M$을 $\\dfrac{S}{N}$로 다시 쓸 수 있습니다. 여기에서 $S$는 모든 단어 임베딩의 합입니다(패딩 토큰은 0 벡터이므로 합에서는 패딩 토큰을 포함했는지 여부가 문제가 안됩니다). 따라서 이 함수는 $M \\times \\sqrt N = \\dfrac{S}{N} \\times \\sqrt N = \\dfrac{S}{\\sqrt N \\times \\sqrt N} \\times \\sqrt N= \\dfrac{S}{\\sqrt N}$를 반환해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 리뷰의 평균 임베딩을 계산하고 리뷰의 단어 개수의 제곱근을 곱하기 위해 간단한 함수를 정의합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.535534 , 4.9497476, 2.1213205],\n",
       "       [6.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mean_embedding(inputs):\n",
    "    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n",
    "    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)    \n",
    "    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n",
    "    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words\n",
    "\n",
    "another_example = tf.constant([[[1., 2., 3.], [4., 5., 0.], [0., 0., 0.]],\n",
    "                               [[6., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])\n",
    "compute_mean_embedding(another_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과가 올바른지 확인해 보죠. 첫 번째 리뷰에는 2개의 단어가 있습니다(마지막 토큰은 `<pad>` 토큰을 나타내는 0벡터입니다). \n",
    "\n",
    "이 두 단어의 평균 임베딩을 계산하고 그 결과에 2의 제곱근을 곱해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3.535534 , 4.9497476, 2.1213202]], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(another_example[0:1, :2], axis=1) * tf.sqrt(2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다. 두 번째 리뷰를 확인해 보죠. 이 리뷰는 하나의 단어만 가지고 있습니다(두 개의 패딩 토큰은 무시합니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[6., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(another_example[1:2, :1], axis=1) * tf.sqrt(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완벽하군요. 이제 최종 모델을 훈련할 차례입니다. 이전과 동이하지만 `BagOfWords` 층을 `Embedding` 층과 `compute_mean_embedding`을 호출하는 `Lambda` 층으로 바꿉니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 20\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    keras.layers.Embedding(input_dim=n_tokens,\n",
    "                           output_dim=embedding_size,\n",
    "                           mask_zero=True), # <pad> tokens => zero vectors\n",
    "    keras.layers.Lambda(compute_mean_embedding),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f.\n",
    "_문제: 모델을 훈련하고 얼마의 정확도가 나오는지 확인해보세요. 가능한 한 훈련 속도를 빠르게 하기 위해 파이프라인을 최적화해보세요._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 18s 19ms/step - loss: 0.5548 - accuracy: 0.7078 - val_loss: 0.5200 - val_accuracy: 0.7318\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 18s 20ms/step - loss: 0.4950 - accuracy: 0.7553 - val_loss: 0.5144 - val_accuracy: 0.7406\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 19s 21ms/step - loss: 0.4846 - accuracy: 0.7612 - val_loss: 0.5071 - val_accuracy: 0.7434\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 18s 20ms/step - loss: 0.4762 - accuracy: 0.7638 - val_loss: 0.5101 - val_accuracy: 0.7422\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 19s 20ms/step - loss: 0.4700 - accuracy: 0.7634 - val_loss: 0.5164 - val_accuracy: 0.7399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2da1b822620>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩을 사용해서 더 나아지지 않았습니다(16장에서 이를 개선해 보겠습니다). 파이프라인은 충분히 빨라 보입니다(앞서 최적화했습니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g.\n",
    "_문제: `tfds.load(\"imdb_reviews\")`와 같이 TFDS를 사용해 동일한 데이터셋을 간단하게 적재해보세요._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"imdb_reviews\")\n",
    "train_set, test_set = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for example in train_set.take(1):\n",
    "    print(example[\"text\"])\n",
    "    print(example[\"label\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916268a5c6dcd25200736720d94968f5c0533c421c8ed3589928c0deacd85b5f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('tf_pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
