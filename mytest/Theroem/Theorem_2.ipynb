{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"image save:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Decision Tree(의사결정 나무)**\n",
    "\n",
    "Rule 기반 의사결정 모델\n",
    "\n",
    "* Binary Question(이진 질의)의 분류 규칙을 바탕으로 Root Node의 질의 결과에 따라 Branch(가지)를 타고 이동\n",
    "\n",
    "* 최종적으로 분류 또는 예측값을 나타내는 Leaf까지 도달함\n",
    "\n",
    "#### 특징\n",
    "\n",
    "* 지도 학습 알고리즘의 일종\n",
    "* Rule은 Entropy가 가장 작은 방향으로 학습\n",
    "* 종류\n",
    "  * 범주형 : Classification Tree, Entropy가 낮은 방향으로 Rule 결정\n",
    "  * 수치형 : Regression Tree, Variance가 낮은 방향으로 Rule 결정\n",
    "* 용어\n",
    "  * Root Node : 최상위 노드\n",
    "    * Splitting : 하위 노드로 분리되는 행위\n",
    "    * Branch : 노드들의 연결(Sub-Tree)\n",
    "  * Decision Node : 2개의 하위노드로 분리되는 노드\n",
    "    * Parent Node : 분리가 발생하는 노드\n",
    "  * Leaf(Terminal Node) : 더이상 분리되지 않는 최하위 노드\n",
    "    * Child Node : 분리가 발생한 후 생성되는 노드\n",
    "\n",
    "#### Model Capacity in Decision Tree\n",
    "\n",
    "* 의사결정 나무는 규칙 기반으로 직관적으로 이해하기 쉽고, 설명력(Model Capacity)이 좋은 알고리즘\n",
    "* 각 노드별 불순도(Impurity, = Entropy)에 기반한 최적의 분류 규칙을 적용함\n",
    "  * Splitting 과정을 반복하면서 의사결정 나무가 성장하며 모델의 설명력이 증가함\n",
    "  * 나무가 성장하면서 설명력이 증가하면 과적합이 발생할 수 있음\n",
    "* Leaf는 순도(동질성)이 높은 적은 수의 데이터 포인트를 포함함\n",
    "  * 순도 높은 결과를 만들기 위해 순도 높은 Leaf가 나올 때까지 Recursive Partitioning을 수행함\n",
    "  * Leaf들의 불순도는 0\n",
    "\n",
    "#### Overfitting(과적합)\n",
    "* 노드들은 불순도가 낮은 방향으로 분리됨\n",
    "* 노드들이 분리되면서 너무 복잡하고 큰 의사결정나무 모델을 생성하여 과적합 문제가 발생됨\n",
    "\n",
    "#### Pruning(가지치기)\n",
    "\n",
    "* 과적합 예방 및 모델 성능향상 목적으로 의사결정나무의 파라미터를 조정하는 방법(Hyper Parameter)\n",
    "* 보통 사후에 진행하고, 모델을 경량화할 수 있는 방법\n",
    "* max_depth : 의사결정나무의 성장 깊이 지정\n",
    "* min_samples_leaf : 리프에 들어가는 최소 샘플의 개수 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불순도(= Entropy) 계산 방식\n",
    "\n",
    "트리 모델에서는 불순도(Impurity)가 낮은 방식으로 트리가 만들어지는데, Entropy와 Gini Index가 있다.\n",
    "\n",
    "#### 1) Entropy\n",
    "\n",
    "* 분리 정보 이득(질문 전 Entropy - 질문 후 Entropy(불순도))이 큰 특징으로 분리 발생\n",
    "* 분리 정보 이득을 비교하여 이득이 큰 Feature로 분리 발생\n",
    "$\n",
    "-(\\sum\\limits_{i=1}^n p_i \\log_2 p_i ) $\n",
    "\n",
    "* 분리 정보 이득 계산 예\n",
    "  * ‘소득’ Feature로 분리해야할지, ‘학생’ Feature로 분리해야할지 분리 정보 이득을 계산하여 이득이 큰 쪽으로 노드 분리\n",
    "  * ‘학생’ Feature 계산은 생략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n학생\\t  소득\\t연체\\n네\\t    없음\\tYes\\n아니오  없음\\tNo\\n네\\t    없음\\tYes\\n아니오\\t있음\\tNo\\n네\\t    없음\\tYes\\n아니오\\t없음\\tNo\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "학생\t  소득\t연체\n",
    "네\t    없음\tYes\n",
    "아니오  없음\tNo\n",
    "네\t    없음\tYes\n",
    "아니오\t있음\tNo\n",
    "네\t    없음\tYes\n",
    "아니오\t없음\tNo\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) (소득)질문 후 Entropy 계산\n",
    "  * $p(\\text{있음}) \\times E(Yes, No) + p(\\text{없음}) \\times E(Yes, No)$\n",
    "\n",
    "    $= \\frac{1}{6} \\times E(0, 1) + \\frac{5}{6} \\times E(3, 2)$\n",
    "\n",
    "    $=\\frac{1}{6} \\times (-\\frac{0}{1} \\times \\log_2\\frac{0}{1} - \\frac{1}{1} \\times \\log_2\\frac{1}{1}) + \\frac{5}{6} \\times (-\\frac{3}{5} \\times \\log_2\\frac{3}{5} - \\frac{2}{5} \\times \\log_2\\frac{2}{5})$\n",
    "    \n",
    "    $= 0.966$\n",
    "\n",
    "2) (소득)분리 정보 이득 계산\n",
    "  * $1 − 0.966 = 0.034$\n",
    "\n",
    "3) (학생)분리 정보 이득이 1이므로 ‘학생’ Feature로 노드가 분리됨\n",
    "\n",
    "#### 2) Gini Impurity Index\n",
    "\n",
    "* sklearn의 기본 불순도 계산 방식\n",
    "* 지니 불순도 지수(1 - 특징 지니 지수)가 작은 특징으로 분리 발생(분리 정보 이득과 반대 개념)\n",
    "* 특징 지니 지수가 클 수록 불순도가 낮음\n",
    "$\n",
    "1-\\sum\\limits_{i=1}^n {p_i}^2 $\n",
    "\n",
    "* 지니 불순도 지수 계산 예\n",
    "  * ‘소득’ Feature로 분리해야할지, ‘학생’ Feature로 분리해야할지 지니불순도 지수를 계산해 작은쪽으로 노드 분리\n",
    "  * ‘학생’ Feature 계산은 생략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n학생\\t  소득\\t연체\\n네\\t    없음\\tYes\\n아니오\\t없음\\t No\\n네\\t    없음\\tYes\\n아니오\\t있음\\t No\\n네\\t    없음\\tYes\\n아니오\\t없음\\t No\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "학생\t  소득\t연체\n",
    "네\t    없음\tYes\n",
    "아니오\t없음\t No\n",
    "네\t    없음\tYes\n",
    "아니오\t있음\t No\n",
    "네\t    없음\tYes\n",
    "아니오\t없음\t No\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) (소득)특징 지니 지수 계산\n",
    "\n",
    "있음 : ${\\frac{0}{1}}^2 + {\\frac{1}{1}}^2 = 1$\n",
    "\n",
    "없음 : ${\\frac{3}{5}}^2 + {\\frac{2}{5}}^2 = 0.52$\n",
    "\n",
    "특징 지니 지수 : $\\frac{1}{6} * 1 + \\frac{5}{6} * 0.52 $\n",
    "\n",
    "2) (소득)지니 불순도 지수 계산\n",
    "\n",
    "$1 − 0.6 = 0.4$\n",
    "\n",
    "#### Feature Importance\n",
    "\n",
    "모델에 대한 Feature의 기여도(중요도)\n",
    "\n",
    "트리 모델 혹은 트리 기반의 앙상블 모델에서는 Feature Importance를 확인할 수 있음(Random Forest, …)\n",
    "\n",
    "* 1 : 기여도 높음 / 0 : 기여도 없음\n",
    "* Feature Importance가 0이라 할지라도, 직접 모델에 적용시켜봐야 실제 기여도를 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GridSearchCV(for Hyparameter Tuning)**\n",
    "\n",
    "sklearn에서 Hyperparameter Tuning 시 사용 되는 방법\n",
    "\n",
    "입력한 parameters의 경우의 수를 모두 모델에 적용하여, 지정한 score가 높은 parameters의 조합을 찾아내는 클래스\n",
    "\n",
    "* 무조건 모델이 최적화 되었다고 맹신할 수는 없음\n",
    "* 모든 파라미터들의 조합을 확인하므로 시간이 오래 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **교차 검증(Cross Validation)**\n",
    "\n",
    "#### Overfitting 방지를 위해 수행되는 검증 방법\n",
    "\n",
    "* 다양하게 Training Data와 Validation Data를 변경하면서 Model Validation 수행\n",
    "* Validation을 한 번만 수행하면 특정 Data에만 최적화 될수 있기 때문에 교차 검증 실시\n",
    "\n",
    "#### K-Fold Cross Validation\n",
    "\n",
    "Training Data를 무작위로 균등하게 K개 그룹으로 나누어서 검증하는 방법\n",
    "\n",
    "최적의 파라미터를 찾기 위한 방법 중 하나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"K-fold.png\"\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "show_img = mpimg.imread(os.path.join(images_path, filename))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(show_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과정\n",
    "* Training Data를 K개 그룹으로 나눔\n",
    "* 각 그룹(Training Data)을 (K-1) 개의 Training Fold와 1개의 Validation Fold로 나눔\n",
    "* Training Fold로 학습을 진행하고, Validation Fold에 대해 성능을 측정함\n",
    "* 총 K개 그룹 결과의 평균을 측정하여 모델의 최적 parameter를 찾음\n",
    "* 최적 parameter로 모델을 학습시킨 후 Test Data에 검증을 수행함\n",
    "\n",
    "#### 특징\n",
    "  * K : Hyperparameter\n",
    "    * 일반적으로 5 ~ 10 사용\n",
    "  * Data가 충분히 많다면, K-Fold Cross Validation\n",
    "  * Data가 매우 적다면, 데이터 개수만큼 Cross Validation 수행(LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제\n",
    "GridSearchCV에서 cv 파라미터로 교차 검증을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "grid_cv = GridSearchCV(Model_rf,\n",
    "                       param_grid = params,\n",
    "                       scoring = 'accuracy',\n",
    "                       cv = KFold(n_splits = 5,\n",
    "                                  random_state = 2045),\n",
    "                       refit = True,\n",
    "                       n_jobs = -1)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **랜덤 포레스트(Random Forest)**\n",
    "\n",
    "### 앙상블(Ensemble)\n",
    "\n",
    "여러가지 모델을 사용하여 Accuracy를 개선하는 방법\n",
    "\n",
    "#### Ensemble의 종류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Ensemble.png\"\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "show_img = mpimg.imread(os.path.join(images_path, filename))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(show_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Random Forest(랜덤 포레스트)**\n",
    "\n",
    "의사결정나무(Decision Tree)의 앙상블(Ensemble)\n",
    "\n",
    "* 의사결정나무에서 나무를 여러개 만드는 것\n",
    "* 지도학습의 일종\n",
    "\n",
    "#### 특징\n",
    "* 다수의 의사결정 나무들의 결과로부터 모델을 생성함\n",
    "* 모델 생성 시 다양성(Diversity)과 임의성(Random) 부여\n",
    "* 모델 Accuracy를 높이고 및 Overfitting 발생 가능성을 낮춤\n",
    "* 일반적으로 의사결정나무 보다 성능이 좋음\n",
    "\n",
    "### 1) 다양성(Diversity)과 임의성(Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Diversity_random.png\"\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "show_img = mpimg.imread(os.path.join(images_path, filename))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(show_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다양성(Diversity)\n",
    "\n",
    "##### **Bagging(Bootstrap + Aggregating)**\n",
    "\n",
    "나무를 다양하게 생성하고, 다양한 나무로부터 나온 결과들을 통합하는 것\n",
    "\n",
    "##### **Bootstrap**\n",
    "\n",
    "다양성을 위해 Bootstrap 방식으로 새로운 데이터를 생성함\n",
    "\n",
    "* 원본 Data를 사용하여 여러 개의 서로 다른 Train Data를 생성함\n",
    "  * 생성된 Train Data 마다 별도의 의사결정나무 모델을 생성함\n",
    "  * 의사결정나무 모델 개수를 조정하기 위한 Hyperparameter : n_estimators\n",
    "* Train Data는 Original Data에서 단순 복원 임의추출법으로 생성(중복이 있음)\n",
    "  * 예를 들어 Original Data에 데이터포인트가 3개이고 nestimators가 3이라면,\n",
    "    ($X_1, X_2, X_3$), ($X_1, X_1, X_3$), ($X_3, X_2, X_3$) 으로 Train data로부터 3개의 Bootstrap Data를 생성한다.\n",
    "\n",
    "##### **Aggregating**\n",
    "\n",
    "다양성을 위해 여러개 Bootstrap 모델의 결과를 통합함\n",
    "\n",
    "* Hyperparameter인 모델의 개수(n_estimators)에 따라 통합 결과가 달라짐\n",
    "* 모델별 통합 방법\n",
    "  * 분류 모델 : 다수결 또는 가중치를 적용하여 통합\n",
    "    * $\\hat{y}=(1,0,0,0,1,1,1,1,1)=1$\n",
    "      *홀수로 주지 않아도, 50대 50으로 나올 경우는 매우 드물기 때문에 짝수로 주어도 됨\n",
    "\n",
    "  * 예측 모델 : 평균값 또는 가중평균값으로 통합\n",
    "    * $\\hat{y} = (77, 75, 76, 77, 76) = 76.2$\n",
    "\n",
    "\n",
    "#### 임의성(Random)\n",
    "\n",
    "##### **Random Subspace**\n",
    "\n",
    "임의성을 위해 의사결정 나무 생성 시 Feature를 무작위로 선택하는 것\n",
    "\n",
    "* 원본 Feature에서 무작위로 입력 Feature를 추출하여 적용함(하나의 입력에 Feature 중복이 없는 비복원 추출)\n",
    "* Decision Tree 보다 다양한 Feature를 활용함\n",
    "* 입력 변수 개수 조정을 위한 Hyperparameter : max_features\n",
    "  * default : $\\sqrt{Feature count}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Hyperparameter\n",
    "\n",
    "일반적으로 조정되는 파라미터는 상위 3개\n",
    "\n",
    "##### **종류** \n",
    "1. n_estimators : 모델에 사용되는 의사결정나무 개수\n",
    "2. max_features : 분할에 사용되는 Feature의 개수\n",
    "3. max_depth : 트리 모델의 최대 깊이\n",
    "4. max_leaf_nodes : Leaf 최대 개수\n",
    "5. min_samples_split : 분할을 위한 최소한의 샘플 데이터 개수\n",
    "6. min_samples_leaf : Leaf가 되기 위한 최소한의 샘플 데이터 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **규제화(Regularization)**\n",
    "\n",
    "#### **Overfitting**\n",
    "\n",
    "모델이 Train 데이터에만 최적화된 상태\n",
    "\n",
    "Loss가 Train Data에 대해서만 낮지만, Validation Data에 대해서는 높음 - 이걸 막아야 함\n",
    "\n",
    "##### Overfitting 발생 원인\n",
    "1. Data point 개수가 적을 때\n",
    "2. Model Capacity가 높을 때\n",
    "+ 파라미터($w_i$) 개수가 많은 경우\n",
    "\n",
    "#### **Regulation(규제화)**\n",
    "\n",
    "Model이 Train Data에 너무 학습되지 않도록 방해하는 것\n",
    "\n",
    "Overfitting을 회피할 목적으로 파라미터 개수를 줄이는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"regulation.png\"\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "show_img = mpimg.imread(os.path.join(images_path, filename))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(show_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* w의 차수가 크면 비용 함수가 구불구불해지면서 모든 데이터에 맞게 되는 Overfitting이 일어난다.\n",
    "* 이러한 성질을 최소화 하기 위해 특정 값을 더하는데, 무엇을 더하는지에 따라 모델이 달라진다.\n",
    "* 특정 값을 더하면 지속적으로 노이즈가 발생하여 Loss 증가하게 만든다.\n",
    "\n",
    "#### **Ridge Regression(릿지 회귀)**\n",
    "\n",
    "MSE 식에 $\\alpha \\sum\\limits_{j=1}^m {w_j}^2$ 를 더해 w를 제어.\n",
    "\n",
    "규제 방식 : L2\n",
    "\n",
    "* $\\alpha$ = 1(default)\n",
    "* $\\alpha$ 를 높이면 계수를 0에 더 가깝게 만들어 Train 모델의 성능은 나빠지지만 일반화에는 도움이 된다.\n",
    "* $\\alpha$ 를 낮추면 계수에 대한 제약이 풀리면서 과적합이 일어날 가능성이 증가한다.\n",
    "* Test data에 대한 성능이 높아질 때까지 alpha 값을 줄이며 조절한다(Hyperparameter).\n",
    "* 성능이 비슷하다면, 보통 Ridge와 Lasso 중 Ridge를 선호한다(어떤 계수도 0이 되지 않기 때문).\n",
    "\n",
    "#### **Lasso Regression(라쏘 회귀)**\n",
    "\n",
    "MSE 식에 $\\alpha \\sum\\limits_{j=1}^m \\left\\vert {w_j} \\right\\vert$ 를 더해 w를 제약\n",
    "\n",
    "규제 방식 : L1\n",
    "\n",
    "* Ridge와 같이 계수를 0에 가깝게 만들려고 하는데, 방식이 조금 다르다.\n",
    "* L1 규제 결과로 어떤 계수는 정말 0이 되는데, 모델에서 완전히 제외되는 Feature가 생긴다\n",
    "* (Feature selection이 자동으로 이루어진다고 볼 수 있음).\n",
    "* $\\alpha$ = 1(default)\n",
    "* $\\alpha$ 를 높이면 계수를 0에 더 가깝게 만들어 Train 모델의 성능은 나빠지지만 일반화에는 도움이 된다.\n",
    "* $\\alpha$ 를 낮추면 계수에 대한 제약이 풀리면서 과적합이 일어날 가능성이 증가한다.\n",
    "  * 예를 들어, 과소적합이 발생하여 $\\alpha$ 를 줄일 때 max_iter(반복 실행하는 최대 횟수)의 기본값은 늘린다.\n",
    "* Feature가 많고 그 일부만 중요하다면(0이 되는 경우 발생 고려) Lasso를 선호할 수 있다.\n",
    "\n",
    "#### **ElasticNet(엘라스틱넷)**\n",
    "\n",
    "Ridge와 Lasso를 결합한 회귀 $(l_1 \\times \\sum\\limits_{j=1}^m \\left\\vert {w_j} \\right\\vert + \\dfrac{1}{2} \\times l_2 \\times \\sum\\limits_{j=1}^m {w_j}^2) $\n",
    "\n",
    "규제 방식 : L1 + L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **K-Nearest Neighbors(KNN)**\n",
    "\n",
    "데이터 분류 시 이웃한 데이터 포인트의 분류를 바탕으로 하는 알고리즘\n",
    "\n",
    "데이터의 Label을 정의할 때 주변 데이터들의 Label을 조사하여 다수결로 K개 이상이며, 가장 많은 것의 Label로 정의함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"knn.png\"\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "show_img = mpimg.imread(os.path.join(images_path, filename))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(show_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K : 최근접 이웃의 개수, 하이퍼파라미터\n",
    "* 최적의 K 값을 찾기 위해 파라미터를 튜닝(Cross Validation)\n",
    "* 사기 탐지(Fraud Detection), 이상 감지(Anomaly Detection)에 적합\n",
    "* 데이터 시각화를 통해 용이하게 분류 가능\n",
    "  * 다차원 공간에서 계산량이 급격히 증가함\n",
    "  * 예측자의 개수가 적고, 분류의 크기가 비슷할 때 사용 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE(Over Sampling)\n",
    "\n",
    "Target 데이터 수가 불균형할 때 상대적으로 부족한 데이터를 Over samplig(오버 샘플링) 하는 방법\n",
    "\n",
    "* 이진 분류에서 Target 데이터 수가 불균형하여 SMOTE를 사용하면, 두 개의 Target 데이터 수는 똑같아 진다.\n",
    "\n",
    "* Recall을 올리기 위해 사용했으나 Precision, F1-Score가 떨어질 수 있으므로 조심해서 사용해야 한다.\n",
    "\n",
    "분류 실습 : 신용카드 사기 검출 (Credit Card Fraud Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **연관 규칙(Association Rules)**\n",
    "\n",
    "데이터 사이의 연관된 규칙을 찾는 방법\n",
    "\n",
    "특정 사건 발생 시 함께 자주 발생하는 다른 사건(조건부 확률)의 규칙(Rule)\n",
    "\n",
    "* 비지도 학습의 일종\n",
    "* 유사도를 측정하는 방법 중 하나\n",
    "* 방향성이 존재함\n",
    "  * Confidence, Lift : A $\\rightarrow$ B (A를 산사람이 B도 구매)\n",
    "* 예\n",
    "  * 상품 A를 구매한 고객이 상품 B를 함께 구매할 확률(구매 패턴) 확인\n",
    "  * 마케팅에서 고객별 장바구니 내 품목 간 관계 분석\n",
    "\n",
    "\n",
    "### Support, Confidence, Lift\n",
    "\n",
    "##### **Support**(지지도) - 전체 거래에 대한 A와 B가 동시에 발생할 확률\n",
    "\n",
    "특정 품목 집합이 얼마나 자주 등장하는지 확인(예 : 빈번하게 판매되는 물품 확인)\n",
    "\n",
    "* 특정 품목 집합을 포함하는 거래의 비율로 계산\n",
    "* 방향성 없음(A $\\rightarrow$ B == B $\\rightarrow$ A)\n",
    "\n",
    "$\n",
    "support = \\dfrac{\\text{A와 B가 포함된 거래 수}}{\\text{전체 거래 수}} $\n",
    "\n",
    "\n",
    "\n",
    "##### **Confidence**(신뢰도)\n",
    "\n",
    "상품 A가 존재할 때 상품 B가 나타나는 빈도\n",
    "\n",
    "* 상품 A가 포함된 거래 중, 상품 B를 포함하는 거래 비율로 계산\n",
    "* 방향성 있음(A(원인) $\\rightarrow$ B(결과))\n",
    "\n",
    "$\n",
    "Confidence = \\dfrac{\\text{A(조건)와 B(결과)가 동시에 포함된 거래 수}}{\\text{A(조건)를 포함한 거래 수}} $\n",
    "\n",
    "* 감자칩을 사면 75% 확률로 맥주를 구매한다고 볼 수 있지만,\n",
    "* 맥주의 판매 빈도를 고려하지 않고 감자칩의 판매 빈도만 고려했기 때문에 맥주 자체가 자주 거래되는 상품이라면 신뢰도를 부풀릴 수 있음\n",
    "* Lift를 활용하여 두 물품 모두의 기반 빈도(Base Frequency)를 고려해야 함\n",
    "\n",
    "\n",
    "##### Lift(향상도)\n",
    "\n",
    "상품 A와 상품 B가 함께 팔리는 빈도\n",
    "\n",
    "* 두 물품이 각각 얼마나 자주 거래되는지를 고려함\n",
    "* 방향성 있음(A(원인) $\\rightarrow$ B(결과))\n",
    "\n",
    "* Lift 값\n",
    "1 : 두 물품 사이에 연관성이 없음(독립 사건)\n",
    "$< 1 $: 상품 A 거래 시 상품 B가 거래될 가능성 작음\n",
    "$> 1 $: 상품 A 거래 시 상품 B가 거래될 가능성 있음\n",
    "\n",
    "$\n",
    "Lift = \\frac{{Confidence(A \\rightarrow B)}}{{Support(B)}}$\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "813af78ecda15588a7e82817c6b6453ec390e9c163778a4ec46b9b973fd11dd3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf_pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
