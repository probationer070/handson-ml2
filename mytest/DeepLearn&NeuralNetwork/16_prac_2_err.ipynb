<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 텐서 플로의 정보 출력 억제하기\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # GPU 장치 지정\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)   # 이거 쓰지 마셈 ㅈㄴ 출력 더러움\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"감지된 GPU가 없습니다. GPU가 없으면 LSTM과 CNN이 매우 느릴 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "_연습문제: 날짜 문자열 포맷을 변환하는 인코더-디코더 모델을 훈련하세요(예를 들어, ‘April 22, 2019’에서 ‘2019-04-22’로 바꿉니다)._\n",
    "\n",
    "먼저 데이터셋을 만들어 보죠. 1000-01-01 ~ 9999-12-31 사이의 랜덤한 날짜를 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "# strftime()의 %B 포맷은 로케일에 의존하기 때문에 사용할 수 있습니다.\n",
    "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "\n",
    "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "\n",
    "    x = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 입력과 출력 형식에 맞춘 랜덤한 몇 개의 날짜입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Target                   \n",
      "--------------------------------------------------\n",
      "September 20, 7075       7075-09-20               \n",
      "May 15, 8579             8579-05-15               \n",
      "January 11, 7103         7103-01-11               \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_dates = 3\n",
    "x_example, y_example = random_dates(n_dates)\n",
    "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
    "print(\"-\" * 50)\n",
    "for idx in range(n_dates):\n",
    "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력에 가능한 전체 문자를 나열해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
    "INPUT_CHARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 다음은 출력에 가능한 전체 문자입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = \"0123456789-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 연습문제에서처럼 문자열을 문자 ID 리스트로 바꾸는 함수를 작성해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(x_example[0], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)    # 비정형 텐서\n",
    "    return (X + 1).to_tensor() # using 0 as the padding token ID\n",
    "\n",
    "def create_dataset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, Y_train = create_dataset(10000)\n",
    "X_valid, Y_valid = create_dataset(2000)\n",
    "X_test, Y_test = create_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫 번째 버전: 기본적인 seq2seq 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 가장 간단한 모델을 시도해 보겠습니다: 입력 시퀀스가 먼저 (임베딩 층 뒤에 하나의 LSTM 층으로 구성된) 인코더를 통과하여 벡터로 출력됩니다. 그 다음 이 벡터가 (하나의 LSTM 층 뒤에 밀집 층으로 구성된) 디코더로 들어가 벡터의 시퀀스를 출력합니다. 각 벡터는 가능한 모든 출력 문자에 대한 추정 확률입니다.\n",
    "\n",
    "디코더는 시퀀스를 입력으로 기대하기 때문에 가능한 가장 긴 출력 시퀀스만큼 (인코더의 출력) 벡터를 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 12s 23ms/step - loss: 1.8255 - accuracy: 0.3456 - val_loss: 1.3841 - val_accuracy: 0.4839\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.2713 - accuracy: 0.5414 - val_loss: 1.1274 - val_accuracy: 0.6011\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.9783 - accuracy: 0.6471 - val_loss: 0.8662 - val_accuracy: 0.6841\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.9566 - accuracy: 0.6592 - val_loss: 1.2517 - val_accuracy: 0.5620\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.8473 - accuracy: 0.6914 - val_loss: 0.7171 - val_accuracy: 0.7158\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.5668 - accuracy: 0.7828 - val_loss: 0.4781 - val_accuracy: 0.8113\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4041 - accuracy: 0.8374 - val_loss: 0.5787 - val_accuracy: 0.7808\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.6204 - accuracy: 0.7887 - val_loss: 0.3555 - val_accuracy: 0.8695\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.2807 - accuracy: 0.9050 - val_loss: 0.2290 - val_accuracy: 0.9280\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1749 - accuracy: 0.9518 - val_loss: 0.1305 - val_accuracy: 0.9672\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2356 - accuracy: 0.9388 - val_loss: 0.1524 - val_accuracy: 0.9646\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.0788 - accuracy: 0.9868 - val_loss: 0.0570 - val_accuracy: 0.9905\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0416 - accuracy: 0.9947 - val_loss: 0.0364 - val_accuracy: 0.9955\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0271 - accuracy: 0.9973 - val_loss: 0.0253 - val_accuracy: 0.9980\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0183 - accuracy: 0.9988 - val_loss: 0.0172 - val_accuracy: 0.9991\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0127 - accuracy: 0.9994 - val_loss: 0.0120 - val_accuracy: 0.9994\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0089 - accuracy: 0.9997 - val_loss: 0.0088 - val_accuracy: 0.9997\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0065 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9998\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9999\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "max_output_length = Y_train.shape[1]\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
    "                           output_dim=embedding_size,\n",
    "                           input_shape=[None]),\n",
    "    keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder,\n",
    "    keras.layers.RepeatVector(max_output_length),\n",
    "    decoder\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋아 보이네요, 100% 검증 정확도를 달성했습니다! 이 모델을 사용해 예측을 만들어 보죠. 문자 ID 시퀀스를 문자열로 바꾸는 함수를 작성하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
    "    return [\"\".join([(\"?\" + chars)[index] for index in sequence])\n",
    "            for sequence in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 사용해 샘플 날짜를 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_date_strs([\"September 17, 2009\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "#ids = model.predict_classes(X_new)\n",
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완벽합니다! :)\n",
    "\n",
    "하지만 (가장 긴 날짜에 해당하는) 길이가 18인 입력 문자열에서만 모델이 훈련되었기 때문에 짧은 시퀀스에서는 잘 동작하지 않습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-02\n",
      "1789-09-14\n"
     ]
    }
   ],
   "source": [
    "#ids = model.predict_classes(X_new)\n",
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런! 패딩을 사용해 훈련할 때와 동일한 길이의 시퀀스를 전달해야 할 것 같습니다. 이를 위해 헬퍼 함수를 작성해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = X_train.shape[1]\n",
    "\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = prepare_date_strs(date_strs)\n",
    "    if X.shape[1] < max_input_length:\n",
    "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    #ids = model.predict_classes(X)\n",
    "    ids = np.argmax(model.predict(X), axis=-1)\n",
    "    return ids_to_date_strs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-05-02', '1789-07-14']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋네요! 물론 더 쉽게 날짜 변환 도구를 만들 수 있습니다(예를 들면, 정규식이나 더 단순한 문자열 조작). 하지만 신경망을 사용하는 것이 더 멋져 보이네요. ;-)\n",
    "\n",
    "하지만 실제 시퀀스-투-시퀀스 문제는 더 어렵습니다. 완벽함을 추구하기 위해 더 강력한 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 번째 버전: 디코더에서 쉬프트된 타깃 주입하기(티처 포싱(teacher forcing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더에세 인코더 출력 벡터를 단순히 반복한 것을 주입하는 대신 한 타임 스텝 오른쪽으로 이동된 타깃 시퀀스를 주입할 수 있습니다. 이렇게 하면 각 타임 스텝에서 디코더는 이전 타깃 문자가 무엇인지 알게 됩니다. 이는 더 복잡한 시퀀스-투-시퀀스 문제를 다루는데 도움이 됩니다.\n",
    "\n",
    "각 타깃 시퀀스의 첫 번째 출력 문자는 이전 문자가 없기 때문에 시퀀스 시작(start-of-sequence, sos)을 나타내는 새로운 토큰이 필요합니다.\n",
    "\n",
    "추론에서는 타깃을 알지 못하므로 디코더에게 무엇을 주입해야 할까요? sos 토큰을 시작해서 한 번에 하나의 문자를 예측하고 디코더에게 지금까지 예측한 모든 문자를 주입할 수 있습니다(나중에 이 노트북에서 더 자세히 알아 보겠습니다).\n",
    "\n",
    "하지만 디코더의 LSTM이 스텝마다 이전 타깃을 입력으로 기대한다면 인코더의 벡터 출력을 어떻게 전달할까요? 한가지 방법은 출력 벡터를 무시하는 것입니다. 그리고 대신 인코더의 LSTM 상태를 디코더의 LSTM의 초기 상태로 사용합니다(이렇게 하려면 인코더의 LSTM과 디코더의 LSTM 유닛 개수가 같아야 합니다).\n",
    "\n",
    "그럼 (훈련, 검증, 테스트를 위한) 디코더의 입력을 만들어 보죠. sos 토큰은 가능한 출력 문자의 마지막 ID + 1으로 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "\n",
    "def shifted_output_sequences(Y):\n",
    "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
    "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)       # axis = 1 or -1 same meaning\n",
    "\n",
    "X_train_decoder = shifted_output_sequences(Y_train)\n",
    "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
    "X_test_decoder = shifted_output_sequences(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 훈련 입력을 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 10), dtype=int32, numpy=\n",
       "array([[12,  8,  1, ..., 10, 11,  3],\n",
       "       [12,  9,  6, ...,  6, 11,  2],\n",
       "       [12,  8,  2, ...,  2, 11,  2],\n",
       "       ...,\n",
       "       [12, 10,  8, ...,  2, 11,  4],\n",
       "       [12,  2,  2, ...,  3, 11,  3],\n",
       "       [12,  8,  9, ...,  8, 11,  3]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와 머임. ㅈㄴ 어렵네, 도데체 128차원을 어떻게 쥐어준걸까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Multi Layer Model에 대해서는 'Neural Network 개념과 MNIST예제' 단원에서 공부하셨을 거라 생각됩니다.\n",
    "\n",
    "# 먼저 Dense Layer를 추가하는 model.add(Dense(12, activation='softmax'))의 경우는 12를 쓰는 이유가 명확합니다.\n",
    "\n",
    "# activation='softmax'와 같이 Activation함수를 softmax를 사용하는 것은 Multinomial Classification을 사용하는 것입니다.\n",
    "\n",
    "# 정확히 어떤 예제인지는 모르겠지만 결과값이 12가지 종류 중 하나를 찾아주는 것 같네요. \n",
    "\n",
    "# 가령 MNIST 손글씨 인식의 경우는 model.add(Dense(10, activation='softmax'))으로 0부터 9까지 총 10가지 종류를 지정하게 되고 보통 이 Layer는 결과를 나타내므로 마지막에 추가됩니다.\n",
    "\n",
    "# model.add(LSTM(128,~의 경우는 128이 Layer에 포함되는 units의 갯수라는 점은 같으나 절대적인 숫자를 의미하지는 않습니다.\n",
    "\n",
    "# 즉 경험치에 의해서 LSTM(Long Short-Term Memory layer)에 128개의 units(dimensionality of the output space)을 줬을때 가장 좋은 결과를 가져오므로 이렇게 쓴 것이고 이 값은 모델을 튜닝하면서 변경하여 사용할 수 있습니다. \n",
    "\n",
    "# 요즘은 최적의 값을 찾아주거나 CNN을 GUI 클라우드에서 쉽게 구해주는 teachable Machine과 같은 서비스가 나와있지만 \n",
    "\n",
    "# 전통적으로 Keras Multi Layer Model을 만들때는 여러 번의 경험치 값을 사용하며 최적의 모델을 만들게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 만듭니다. 이제 더 이상 간단한 시퀀셜 모델이 아니므로 함수형 API를 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 11s 23ms/step - loss: 1.6803 - accuracy: 0.3742 - val_loss: 1.4200 - val_accuracy: 0.4478\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.1912 - accuracy: 0.5587 - val_loss: 0.9085 - val_accuracy: 0.6673\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6464 - accuracy: 0.7686 - val_loss: 0.3891 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2140 - accuracy: 0.9487 - val_loss: 0.1204 - val_accuracy: 0.9783\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.0808 - accuracy: 0.9893 - val_loss: 0.0466 - val_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0304 - accuracy: 0.9988 - val_loss: 0.0255 - val_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0543 - accuracy: 0.9907 - val_loss: 0.0169 - val_accuracy: 0.9998\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0118 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9999\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "lstm_units = 128\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "encoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(INPUT_CHARS) + 1,\n",
    "    output_dim=encoder_embedding_size)(encoder_input)\n",
    "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(\n",
    "    lstm_units, return_state=True)(encoder_embedding)\n",
    "encoder_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "decoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(OUTPUT_CHARS) + 2,\n",
    "    output_dim=decoder_embedding_size)(decoder_input)\n",
    "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(\n",
    "    decoder_embedding, initial_state=encoder_state)\n",
    "decoder_output = keras.layers.Dense(len(OUTPUT_CHARS) + 1,\n",
    "                                    activation=\"softmax\")(decoder_lstm_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_input, decoder_input],\n",
    "                           outputs=[decoder_output])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=10,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델도 100% 검증 정확도를 달성했지만 더 빠릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델을 사용해 몇 가지 예측을 수행해 보죠. 이번에는 한 문자씩 예측해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "\n",
    "def predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
    "    for index in range(max_output_length):\n",
    "        pad_size = max_output_length - Y_pred.shape[1]\n",
    "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, pad_size]])\n",
    "        Y_probas_next = model.predict([X, X_decoder])[:, index:index+1]\n",
    "        Y_pred_next = tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32)\n",
    "        Y_pred = tf.concat([Y_pred, Y_pred_next], axis=1)\n",
    "    return ids_to_date_strs(Y_pred[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 동작하네요! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세 번째 버전: TF-Addons의 seq2seq 구현 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확히 동일한 모델을 만들어 보죠. 하지만 TF-Addon의 seq2seq API를 사용하겠습니다. 아래 구현은 이 노트북의 위에 있는 TFA 예제와 거의 비슷합니다. 다만 모델 입력에 출력 시퀀스 길이를 지정하지 않습니다(하지만 출력 시퀀스의 길이가 매우 다른 프로젝트에서 필요하다면 쉽게 이를 추가할 수 있습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - 32s 90ms/step - loss: 1.6779 - accuracy: 0.3658 - val_loss: 1.4678 - val_accuracy: 0.4189\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 1.3903 - accuracy: 0.4558 - val_loss: 1.2827 - val_accuracy: 0.4981\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 1.0006 - accuracy: 0.6230 - val_loss: 0.8008 - val_accuracy: 0.6977\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 0.4384 - accuracy: 0.8575 - val_loss: 0.2369 - val_accuracy: 0.9438\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.1419 - accuracy: 0.9752 - val_loss: 0.0704 - val_accuracy: 0.9944\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 0.0474 - accuracy: 0.9975 - val_loss: 0.0481 - val_accuracy: 0.9944\n",
      "Epoch 7/15\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.0617 - accuracy: 0.9898 - val_loss: 0.0220 - val_accuracy: 0.9993\n",
      "Epoch 8/15\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 0.0155 - accuracy: 0.9999 - val_loss: 0.0132 - val_accuracy: 0.9998\n",
      "Epoch 9/15\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9998\n",
      "Epoch 10/15\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9999\n",
      "Epoch 11/15\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 0.0865 - accuracy: 0.9807 - val_loss: 0.0104 - val_accuracy: 0.9998\n",
      "Epoch 14/15\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(OUTPUT_CHARS) + 2, decoder_embedding_size)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units)\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
    "                                                 sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings,\n",
    "    initial_state=encoder_state)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=15,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서도 100% 검증 정확도를 달성했습니다! 이 모델을 사용하기 위해 `predict_date_strs()` 함수를 다시 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 더 효율적으로 추론을 수행하는 방법이 있습니다. 지금까지 추론에서 새로운 문자마다 모델을 실행했습니다. 하지만`TrainingSampler` 대신에 `GreedyEmbeddingSampler`를 사용하는 새로운 디코더를 만들 수 있습니다.\n",
    "\n",
    "타임 스텝마다 `GreedyEmbeddingSampler`가 디코더의 출력에 argmax를 계산하고, 디코더 임베딩 층을 통해 토큰 ID를 얻을 수 있습니다. 그다음 다음 타임 스텝에 만들어진 임베딩을 디코더의 LSTM 셀에 주입합니다. 이런 방법을 통해 디코더를 한 번만 실행하여 전체 예측을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer)\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length)\n",
    "batch_size = tf.shape(encoder_inputs)[:1]\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens,\n",
    "    initial_state=encoder_state,\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=0)\n",
    "\n",
    "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
    "                                     outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "몇 개의 노트:\n",
    "* `GreedyEmbeddingSampler`는 `start_tokens`(디코더 시퀀스마다 sos ID를 담은 벡터)와 `end_token`(모델이 이 토큰을 출력할 때 디코더가 시퀀스 디코딩을 멈춥니다)이 필요합니다.\n",
    "* `BasicDecoder`를 만들 때 `maximum_iterations`를 설정해야 합니다. 그렇지 않으면 무한하게 반복할 수 있습니다(적어도 하나의 시퀀스에서 모델이 `end_token`을 출력하지 않는다면). 이렇게 되면 주피터 커널을 재시작해야 합니다.\n",
    "* 모든 디코더 입력이 이전 타임 스텝의 출력을 기반으로 동적으로 생성되기 때문에 디코더 입력은 더 이상 필요하지 않습니다.\n",
    "* 모델의 출력은 `final_outputs.rnn_outputs`의 소프트맥스가 아니라 `final_outputs.sample_id`입니다. 로짓 값을 얻고 싶다면 `final_outputs.sample_id`을 `final_outputs.rnn_outputs`으로 바꾸세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 모델을 사용하는 간단한 함수를 작성하여 날짜 포맷 변환을 수행할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = inference_model.predict(X)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "속도를 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813 ms ± 18.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.1 ms ± 3.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10배 이상 빠릅니다! 긴 시퀀스를 다룰 때 속도는 더 차이가 날 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네 번째 버전: 스케줄 샘플러를 사용하는 TF-Addons의 seq2seq 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**경고**: TF 버그 때문에 이 버전은 텐서플로 2.2 이상에서만 동작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 모델을 훈련할 때 매 타임 스텝 _t_에서 타임 스텝 _t_-1의 타깃 토큰을 모델에게 전달합니다. 하지만 추론에서는 모델이 타임 스텝마다 이전 타깃을 얻을 수 없습니다. 대신에 이전 예측을 사용합니다. 따라서 이런 훈련과 추론 사이에 차이가 실망스러운 성능으로 이어질 수 있습니다. 이를 완화하기 위해 훈련하는 동안 타깃을 예측으로 점진적으로 바꿀 수 있습니다. 이렇게 하려면 `TrainingSampler`를 `ScheduledEmbeddingTrainingSampler`를 바꾸기만 하면 됩니다. 그리고 `sampling_probability`(디코더가 이전 타임 스텝의 타깃 대신에 이전 타임 스텝의 예측을 사용할 확률)를 점진적으로 증가시키기 위해 케라스 콜백을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\tf_pt\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_1_grad/Identity_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_1_grad/Identity_3:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_1_grad/Identity_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Anaconda3\\envs\\tf_pt\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/gradients/grad_ys_0_values:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Anaconda3\\envs\\tf_pt\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 46s 133ms/step - loss: 1.6779 - accuracy: 0.3657 - val_loss: 1.4622 - val_accuracy: 0.4345\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 1.4076 - accuracy: 0.4509 - val_loss: 1.3201 - val_accuracy: 0.4694\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.0720 - accuracy: 0.5938 - val_loss: 0.8251 - val_accuracy: 0.7012\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.6273 - accuracy: 0.7684 - val_loss: 0.4409 - val_accuracy: 0.8407\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.3621 - accuracy: 0.8801 - val_loss: 0.2587 - val_accuracy: 0.9190\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 0.2067 - accuracy: 0.9417 - val_loss: 0.1708 - val_accuracy: 0.9517\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.1659 - accuracy: 0.9599 - val_loss: 0.1002 - val_accuracy: 0.9762\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.0767 - accuracy: 0.9834 - val_loss: 0.0628 - val_accuracy: 0.9860\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.0453 - accuracy: 0.9918 - val_loss: 0.0409 - val_accuracy: 0.9919\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.0295 - accuracy: 0.9949 - val_loss: 0.0247 - val_accuracy: 0.9960\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.0624 - accuracy: 0.9895 - val_loss: 1.3752 - val_accuracy: 0.5474\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 0.0545 - accuracy: 0.9862 - val_loss: 0.0153 - val_accuracy: 0.9979\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 0.0105 - accuracy: 0.9988 - val_loss: 0.0098 - val_accuracy: 0.9990\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9995\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.0877 - accuracy: 0.9801 - val_loss: 0.0124 - val_accuracy: 0.9985\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.0049 - val_accuracy: 0.9996\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9995\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_epochs = 20\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(OUTPUT_CHARS) + 2, decoder_embedding_size)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "#----------------------------------------------------------------------------\n",
    "encoder = keras.layers.LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.ScheduledEmbeddingTrainingSampler(\n",
    "    sampling_probability=0.,\n",
    "    embedding_fn=decoder_embedding_layer)\n",
    "# sampler를 만들 다음 sampling_probability를 지정해야 합니다.\n",
    "# (see https://github.com/tensorflow/addons/pull/1714)\n",
    "sampler.sampling_probability = tf.Variable(0.)\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units)\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
    "                                                 sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings,\n",
    "    initial_state=encoder_state)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "#----------------------------------------------------------------------------\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "def update_sampling_probability(epoch, logs):\n",
    "    proba = min(1.0, epoch / (n_epochs - 10))\n",
    "    sampler.sampling_probability.assign(proba)\n",
    "\n",
    "sampling_probability_cb = keras.callbacks.LambdaCallback(\n",
    "    on_epoch_begin=update_sampling_probability)\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=n_epochs,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid),\n",
    "                    callbacks=[sampling_probability_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도가 100%는 아니지만 충분히 가깝습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론에서도 `GreedyEmbeddingSampler`를 사용해 앞에서와 동일한 작업을 수행할 수 있습니다. 하지만 완성도를 높이기 위해 `SampleEmbeddingSampler`를 사용하겠습니다. 토큰 ID를 찾기 위해 모델 출력에 argmax를 적용하는 대신 로짓 출력에서 랜덤하게 토큰 ID를 샘플링하는 것만 다르고 거의 동일합니다. 텍스트를 생성하는 작업에 유용합니다. `softmax_temperature` 매개변수는 세익스피어와 같은 텍스트를 생성했을 때와 같은 목적을 가집니다(이 매개변수 값이 높을수록 더 랜덤한 텍스트가 생성됩니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_temperature = tf.Variable(1.)\n",
    "\n",
    "inference_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer,\n",
    "    softmax_temperature=softmax_temperature)\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length)\n",
    "batch_size = tf.shape(encoder_inputs)[:1]\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens,\n",
    "    initial_state=encoder_state,\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=0)\n",
    "\n",
    "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
    "                                     outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creative_predict_date_strs(date_strs, temperature=1.0):\n",
    "    softmax_temperature.assign(temperature)\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = inference_model.predict(X)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 온도에서 날짜가 괜찮은 것 같군요. 온도를 조금 더 올려 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1479307-28', '200040?400']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"],\n",
    "                           temperature=5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 날짜가 너무 랜덤하네요. \"창의적인\" 날짜라고 부르죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다섯 번째 버전: TFA seq2seq, 케라스 서브클래싱 API, 어텐션 메커니즘 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제의 시퀀스는 꽤 짧지만 긴 시퀀스를 처리하려면 어텐션 메커니즘을 사용해야 할 것입니다. 직접 어텐션 메커니즘을 구현할 수 있지만 TF-Addons에 있는 구현을 사용하는 것이 더 간단하고 효율적입니다. 케라스 서브클래싱 API를 사용해서 만들어 보죠.\n",
    "\n",
    "**경고**: 텐서플로 버그([이슈](https://github.com/tensorflow/addons/issues/1153) 참조) 때문에 즉시 실행 모드(eager mode)에서 `get_initial_state()` 메서드가 실패합니다. 따라서 지금은 `call()` 메서드에서 `tf.function()`을 자동으로 호출하는 (따라서 그래프 모드로 실행하는) 케라스 서브클래싱 API를 사용해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구현에서는 간단하게 만들기 위해 다시 `TrainingSampler`를 사용합니다(하지만 `ScheduledEmbeddingTrainingSampler`를 사용해 쉽게 바꿀 수 있습니다). 추론에는 `GreedyEmbeddingSampler`를 사용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTranslation(keras.models.Model):\n",
    "    def __init__(self, units=128, encoder_embedding_size=32,\n",
    "                 decoder_embedding_size=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(INPUT_CHARS) + 1,\n",
    "            output_dim=encoder_embedding_size)\n",
    "        self.encoder = keras.layers.LSTM(units,\n",
    "                                         return_sequences=True,\n",
    "                                         return_state=True)\n",
    "        self.decoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(OUTPUT_CHARS) + 2,\n",
    "            output_dim=decoder_embedding_size)\n",
    "        self.attention = tfa.seq2seq.LuongAttention(units)\n",
    "        \n",
    "        decoder_inner_cell = keras.layers.LSTMCell(units)\n",
    "        self.decoder_cell = tfa.seq2seq.AttentionWrapper(\n",
    "            cell=decoder_inner_cell,\n",
    "            attention_mechanism=self.attention)\n",
    "        output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "        \n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(\n",
    "            cell=self.decoder_cell,\n",
    "            sampler=tfa.seq2seq.sampler.TrainingSampler(),\n",
    "            output_layer=output_layer)\n",
    "        self.inference_decoder = tfa.seq2seq.BasicDecoder(\n",
    "            cell=self.decoder_cell,\n",
    "            sampler=tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "                embedding_fn=self.decoder_embedding),\n",
    "                output_layer=output_layer,\n",
    "                maximum_iterations=max_output_length)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        encoder_input, decoder_input = inputs\n",
    "        encoder_embeddings = self.encoder_embedding(encoder_input)\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = self.encoder(\n",
    "            encoder_embeddings,\n",
    "            training=training)\n",
    "        encoder_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "        self.attention(encoder_outputs,\n",
    "                       setup_memory=True)\n",
    "        \n",
    "        decoder_embeddings = self.decoder_embedding(decoder_input)\n",
    "\n",
    "        decoder_initial_state = self.decoder_cell.get_initial_state(\n",
    "            decoder_embeddings)\n",
    "        decoder_initial_state = decoder_initial_state.clone(\n",
    "            cell_state=encoder_state)\n",
    "        \n",
    "        if training:\n",
    "            decoder_outputs, _, _ = self.decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=decoder_initial_state,\n",
    "                training=training)\n",
    "        else:\n",
    "            start_tokens = tf.zeros_like(encoder_input[:, 0]) + sos_id\n",
    "            decoder_outputs, _, _ = self.inference_decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=decoder_initial_state,\n",
    "                start_tokens=start_tokens,\n",
    "                end_token=0)\n",
    "\n",
    "        return tf.nn.softmax(decoder_outputs.rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제작한 빔 서치 코드\n",
    "\n",
    "class DateTranslation_BeamSearch(keras.models.Model):\n",
    "    def __init__(self, units=128, encoder_embedding_size=32,\n",
    "                 decoder_embedding_size=32, beam_width=10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.beam_width = beam_width\n",
    "        self.encoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(INPUT_CHARS) + 1,\n",
    "            output_dim=encoder_embedding_size)\n",
    "        self.encoder = keras.layers.LSTM(units, return_state=True)\n",
    "        self.decoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(OUTPUT_CHARS) + 2,\n",
    "            output_dim=decoder_embedding_size)\n",
    "        \n",
    "        self.decoder_cell = keras.layers.LSTMCell(units)\n",
    "        output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "        \n",
    "        self.decoder = tfa.seq2seq.BeamSearchDecoder(cell=decoder_cell,\n",
    "                                                     beam_width=beam_width,\n",
    "                                                     sampler=tfa.seq2seq.sampler.TrainingSampler(),\n",
    "                                                     output_layer=output_layer)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encoder_input, decoder_input = inputs\n",
    "        encoder_embeddings = self.encoder_embedding(encoder_input)\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = self.encoder(encoder_embeddings)\n",
    "        encoder_state = [encoder_state_h, encoder_state_c]\n",
    "        \n",
    "        self.decoder_cell(encoder_outputs, setup_memory=True)\n",
    "        \n",
    "        decoder_embeddings = self.decoder_embedding(decoder_input)\n",
    "        decoder_initial_state = tfa.seq2seq.tile_batch(encoder_state, multiplier=self.beam_width)\n",
    "        \n",
    "        start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "        decoder_outputs, _, _ = self.decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=decoder_initial_state,\n",
    "                start_tokens=start_tokens,\n",
    "                end_token=0)\n",
    "\n",
    "        return tf.nn.softmax(decoder_outputs.rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# 해당 코드는 빔 검색 코드 구현 테스트 중\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "beam_width = 10\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(OUTPUT_CHARS) + 2, decoder_embedding_size)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "#>>\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "encoder = keras.layers.LSTM(units, return_state=True)\n",
    "#>>\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units)\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.BeamSearchDecoder(cell=decoder_cell,\n",
    "                                        beam_width=beam_width,\n",
    "                                        sampler=sampler,\n",
    "                                        output_layer=output_layer)\n",
    "\n",
    "decoder_initial_state = tfa.seq2seq.tile_batch(encoder_state, multiplier=beam_width)\n",
    "\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(decoder_embeddings, \n",
    "                          start_tokens=start_tokens, end_token=0,\n",
    "                          initial_state=decoder_initial_state)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=15,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# 해당 코드는 빔 검색 코드 구현 테스트 중\n",
    "beam_width = 10\n",
    "decoder = tfa.seq2seq.BeamSearchDecoder(\n",
    "  cell=decoder_cell,\n",
    "  beam_width=beam_width,\n",
    "  output_layer=output_layer)\n",
    "\n",
    "decoder_initial_state = tfa.seq2seq.tile_batch(encoder_state, multiplier=beam_width)\n",
    "\n",
    "outputs, _h, _c = decoder(decoder_embeddings, \n",
    "                          start_tokens=start_tokens, end_token=0,\n",
    "                          initial_state=decoder_initial_state)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "313/313 [==============================] - 44s 113ms/step - loss: 2.1403 - accuracy: 0.2323 - val_loss: 2.0017 - val_accuracy: 0.2682\n",
      "Epoch 2/25\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 1.6870 - accuracy: 0.3930 - val_loss: 1.4963 - val_accuracy: 0.4439\n",
      "Epoch 3/25\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 1.3417 - accuracy: 0.4983 - val_loss: 1.4235 - val_accuracy: 0.4968\n",
      "Epoch 4/25\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 1.2198 - accuracy: 0.5428 - val_loss: 1.2186 - val_accuracy: 0.5328\n",
      "Epoch 5/25\n",
      "313/313 [==============================] - 36s 113ms/step - loss: 1.1109 - accuracy: 0.5798 - val_loss: 1.0594 - val_accuracy: 0.6033\n",
      "Epoch 6/25\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1.6323 - accuracy: 0.4244 - val_loss: 2.1198 - val_accuracy: 0.3026\n",
      "Epoch 7/25\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 1.4907 - accuracy: 0.4628 - val_loss: 1.3666 - val_accuracy: 0.5096\n",
      "Epoch 8/25\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 1.2899 - accuracy: 0.5431 - val_loss: 1.2559 - val_accuracy: 0.5494\n",
      "Epoch 9/25\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 1.1914 - accuracy: 0.5646 - val_loss: 1.1322 - val_accuracy: 0.5775\n",
      "Epoch 10/25\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1.0683 - accuracy: 0.6022 - val_loss: 1.0374 - val_accuracy: 0.6170\n",
      "Epoch 11/25\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 1.1099 - accuracy: 0.5971 - val_loss: 4.0631 - val_accuracy: 0.0904\n",
      "Epoch 12/25\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 1.1439 - accuracy: 0.5976 - val_loss: 1.3012 - val_accuracy: 0.6118\n",
      "Epoch 13/25\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 0.8287 - accuracy: 0.6787 - val_loss: 1.3659 - val_accuracy: 0.6313\n",
      "Epoch 14/25\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 0.6553 - accuracy: 0.7381 - val_loss: 0.8790 - val_accuracy: 0.7159\n",
      "Epoch 15/25\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 0.4669 - accuracy: 0.8155 - val_loss: 0.9016 - val_accuracy: 0.7552\n",
      "Epoch 16/25\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.2923 - accuracy: 0.8977 - val_loss: 0.5761 - val_accuracy: 0.8436\n",
      "Epoch 17/25\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 0.1662 - accuracy: 0.9527 - val_loss: 0.3008 - val_accuracy: 0.9419\n",
      "Epoch 18/25\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.1707 - accuracy: 0.9614 - val_loss: 0.3196 - val_accuracy: 0.9343\n",
      "Epoch 19/25\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0697 - accuracy: 0.9905 - val_loss: 0.0921 - val_accuracy: 0.9901\n",
      "Epoch 20/25\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 0.0390 - accuracy: 0.9955 - val_loss: 0.0432 - val_accuracy: 0.9969\n",
      "Epoch 21/25\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.0234 - accuracy: 0.9983 - val_loss: 0.0302 - val_accuracy: 0.9980\n",
      "Epoch 22/25\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.0669 - accuracy: 0.9870 - val_loss: 0.0656 - val_accuracy: 0.9930\n",
      "Epoch 23/25\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.0136 - accuracy: 0.9995 - val_loss: 0.0228 - val_accuracy: 0.9984\n",
      "Epoch 24/25\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.0093 - accuracy: 0.9998 - val_loss: 0.0156 - val_accuracy: 0.9988\n",
      "Epoch 25/25\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.0069 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9998\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = DateTranslation()\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=25,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = DateTranslation_BeamSearch()\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=25,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% 검증 정확도는 아니지만 매우 가깝습니다. 수렴하는데 조금 오래 걸렸지만 반복마다 파라미터와 계산량이 많습니다. 그리고 스케줄 샘플러를 사용하지 않았습니다\n",
    "\n",
    "이 모델을 사용하기 위해 또 다른 작은 함수를 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date_strs_v2(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    X_decoder = tf.zeros(shape=(len(X), max_output_length), dtype=tf.int32)\n",
    "    Y_probas = model.predict([X, X_decoder])\n",
    "    Y_pred = tf.argmax(Y_probas, axis=-1)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_predict_date_strs_v2([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-Addons에는 몇 가지 흥미로운 기능이 있습니다:\n",
    "* 추론에 `BasicDecoder` 대신 `BeamSearchDecoder`를 사용하면 가장 높은 확률의 문자를 출력하는 대신 디코더가 몇 개의 후보 중에서 가장 가능성 있는 시퀀스만 유지합니다(자세한 내용은 책 16장을 참고하세요).\n",
    "* 입력이나 타깃 시퀀스의 길이가 매우 다르면 마스크를 설정하거나 `sequence_length`를 지정합니다.\n",
    "* `ScheduledEmbeddingTrainingSampler` 보다 더 유연한 `ScheduledOutputTrainingSampler`을 사용하여 타임 스텝 _t_의 출력을 타임 스텝 _t_+1에 주입하는 방법을 결정합니다. 기본적으로 argmax로 ID를 찾지 않고 임베딩 층에 통과시켜 출력을 셀에 바로 주입합니다. 또는 `next_inputs_fn` 함수를 지정하여 셀 출력을 다음 스텝의 입력으로 변환할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "813af78ecda15588a7e82817c6b6453ec390e9c163778a4ec46b9b973fd11dd3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf_pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
>>>>>>> parent of 670e5d0 (v 1.0.098)
